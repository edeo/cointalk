---
title: "Cointalk text analysis with tidytext"
author: "ed"
date: "4/2/2019"
output: html_document
---


(updated 5/5/2019 with new episodes)

Here is a analysis of sentiment in [Cointalk](https://medium.com/s/cointalk), a podcast about the world of bitcoin and crypto currencies, "The official podcast of Bitcoin crashes Hosted by Aaron Lammer and Jay Caspian Kang." It's a great show - if you haven't listened to it I'd recommend that you check it out. 



I took all the Cointalk episodes that have transcriptions and ran them through some sentiment analysis.  Looking at the transcripts, we can see who is more positive , who is more negative, and how that changes over time. 

I figured that a podcast about bitcoin would have a lot of swings in sentiment over time so I thought it'd be a good text to analyze. Also, the transcripts are available for free, which makes it easy to scrape and analyze. I joined medium to support the podcast.


I followed a lot of the instruction from [Text mining with R](https://www.tidytextmining.com/) by Juila Silge and David Robinson. If you want to see the R code in the markdown file, follow this [link here](https://github.com/edeo/cointalk/blob/master/index.Rmd) .

For more information on the sentiments datasets, click [here](https://www.tidytextmining.com/sentiment.html#the-sentiments-dataset) .


```{r , include=FALSE,message=FALSE}

library(rvest)
library(here)
library(readr)
library(stringr)
library(tidyverse)
library(tidytext)

first <- function(x){
  z = str_split(x, ":") %>% unlist(.)
  y= unlist(z[[1]])
  return(y[1])}


second <- function(x){
  z = ifelse(str_detect(x,'Jay Kang:'),str_replace(x,'Jay Kang:', ""),x )
  y = ifelse(str_detect(z,'Aaron Lammer:'),str_replace(z,'Aaron Lammer:', ""),z )
  return(y)
}

```


In the R markdown document, in my github repo, befow is a list of all the cointalk episode webpages that had transcriptions.

```{r, include=FALSE,message=FALSE}


# "https://medium.com/s/cointalk/coin-talk-25-fear-and-loathing-at-a-cryptokitty-auction-33abbcd65b57"


hand_list<- c("coin-talk-2-korean-crypto-mania-and-the-kimchi-spread-8ab23de3e1d9",
              "coin-talk-3-we-survived-the-crash-w-doug-kim-f3e2c7aebbc2",
              "coin-talk-4-do-you-guys-even-believe-in-crypto-own-your-own-casino-5156fa9ff431",
              "coin-talk-5-tether-usdt-is-the-new-disneybucks-ef94876ff3b7",
              "coin-talk-6-how-low-can-you-go-an-interview-with-jameson-lopp-ab5adf8d3a97",
              "7-giancarlo-2020-senate-hearings-on-bitcoin-augurs-first-prediction-marketabout-324e2dd2229c",
              "coin-talk-8-interview-with-nocoiner-tech-journalist-adrian-chen-baf00bf05134",
              "9-privacy-coins-explained-a-deep-dive-into-monero-xmr-and-zcash-zec-5017b84a7ba3",
              "coin-talk-10-telegrams-ton-token-civil-brings-the-blockchain-to-journalism-w-maria-bustillos-913435b278c1",
              "coin-talk-12-what-is-an-ico-c94fa9c4226",
              "coin-talk-13-did-mt-goxs-japanese-trustee-personally-crash-bitcoin-62f62b65aefb",
              "coin-talk-15-whats-so-great-about-the-blockchain-e89c5c5f69b1",
              "coin-talk-11-when-dictators-ico-a02bc72da6e1",
              "coin-talk-14-whats-so-great-about-the-blockchain-dedc38e9413b",
              "coin-talk-16-the-rise-and-fall-of-kang-lammer-americas-worst-crypto-traders-8f32bcb08273",
              "coin-talk-18-the-fundamentals-remain-strong-9a8226e2b802",
              "coin-talk-19-alt-spring-on-the-campus-quad-1deada76e091",
              "coin-talk-20-the-return-of-fomo-kang-w-doug-kim-d3a22a4a3d94",
              "coin-talk-21-will-zrx-be-the-next-coin-added-to-coinbase-cedf82567a7c",
              "coin-talk-22-%EF%B8%8F-the-bitcoin-ransoming-of-aaronlammer-com-be3072fd2668",
              "coin-talk-23-are-ripple-xrp-fans-bots-59c9aa0e192b",
              "24-book-club-the-bitcoin-standard-part-1-a0b9ef7981eb",
              "coin-talk-26-penguin-jetpacks-w-nathaniel-popper-from-the-new-york-times-44652b88526f",
              "coin-talk-27-bitcointopia-where-the-murder-rate-is-100-and-an-interview-with-a-real-xrp-fan-7761ef08d9f5",
              "coin-talk-28-book-club-the-bitcoin-standard-part-2-fc0c096583e9",
              "episode-29-%EF%B8%8F-r-i-p-sumokoin-eaf69e061178",
              "coin-talk-30-interview-with-a-miner-chris-dannen-of-iterative-capital-e36c66b4392b",
              "coin-talk-31-kidnapped-by-the-triads-and-other-shitcoin-adventures-abbbd3c53e10",
              "coin-talk-32-interview-with-saifedean-ammous-economist-and-author-of-the-bitcoin-standard-39652a6612e5",
              "33-how-tezos-went-awry-ed25fb7eab37",
              "coin-talk-34-the-real-slim-satoshi-2254252ee6ff",
              "coin-talk-35-coinbase-goes-shopping-82d529907499",
              "coin-talk-36-how-to-make-dumb-bets-on-augur-w-ledgerstatus-d38d7db33d8f",
              "coin-talk-37-decentralized-assassinations-and-pee-tape-markets-c2d062080c2f",
              "coin-talk-38-no-market-no-bounce-ft-doug-kim-fc4ce3a86c16",
              "coin-talk-39-we-called-a-craigslist-crypto-consultant-58458081de0f",
              "coin-talk-40-mailbag-vol-2-4f5cda373118",
              "coin-talk-41-where-were-you-when-bcash-forked-c7f6bcd55a89",
              "coin-talk-42-excerptoshi-truthers-unite-4eda76b43b0b",
              "coin-talk-43-impressions-of-crypto-china-with-chris-dannen-e5e9f87f24e3",
              "coin-talk-45-the-psychology-of-mass-movements-with-tony-sheng-7b0376514372",
              "46-are-we-ready-to-callabottom-ad9de8faf634",
              "coin-talk-47-bitcoin-bugz-weed-stock-mania-1a37507c2313",
              "coin-talk-48-senate-hearing-jam-session-pt-1-with-zack-voell-cd1e2e7d62b5",
              "coin-talk-49-senate-hearing-jam-session-pt-2-w-brian-patrick-eha-de53e4ebe2b4",
              "coin-talk-50-if-vitalik-is-a-9-10-im-a-2-10-an-interview-with-the-new-yorker-s-nick-239364e3ebd5",
              "episode-51-but-what-do-you-really-think-about-civil-cvl-2b25c0e1f40e",
              "episode-52-hopium-is-a-helluva-drug-w-doug-kim-e0890a77c65b",
              "episode-54-are-we-crypto-influencers-4128e2cc7385",
              "coin-talk-54-brave-bat-b42293422bbf",
              "coin-talk-55-the-bull-case-for-initiative-q-9d7b34c1bda5",
              "coin-talk-56-bcash-2-electric-boogaloo-satoshis-vision-bb0389604f7f",
              "coin-talk-57-crypto-vs-journalism-cd4242706b33",
              "coin-talk-58-super-airdrop-festival-c33752c9c363",
              "coin-talk-59-flashbacks-and-fake-beards-a-crypto-2018-year-in-review-77ee1256aeb7",
              "coin-talk-60-live-on-the-10th-anniversary-of-the-mining-of-the-genesis-block-a687b7c2959f",
              "coin-talk-61-%EF%B8%8Fgrin-the-mimblewimble-protocol-75fe92ed41cf",
              "coin-talk-62-fyre-fest-was-the-original-airdrop-f56862e9118d",
              "coin-talk-63-ska-selling-out-the-bitcoin-etf-fd7f3a789842",
              "cointalk-64-aarons-farm-i-don-t-want-to-mine-in-game-rewards-at-93d47d22b0f9",
              "cointalk-65-slanted-and-enchanted-72a36c1d82b",
              "cointalk-%EF%B8%8F-66-hxro-is-a-crypto-game-that-is-definitely-not-gambling-47595a6c84d5",
              "episode-67-would-oprah-move-the-needle-5b20d9a7910d",
              "cointalk-%EF%B8%8F-68-%EF%B8%8F-hacking-team-wants-to-connect-on-linked-in-90220f283a57",
              "cointalk-%EF%B8%8F-69-the-corruption-episode-f4498a2085c",
              "cointalk-%EF%B8%8F-70-marktoshi-zuckermoto-22e913acdbe6",
              "episode-71-%EF%B8%8F-broke-ass-no-volume-exchanges-64cdea0195ad",
              "cointalk-%EF%B8%8F-72-fomo-kang-3-this-time-its-personal-50a90c3c13",
              "cointalk-%EF%B8%8F-73-crypto-shaman-8949a25982e0",
              "cointalk-%EF%B8%8F-74-when-trolls-get-rekt-31ba67f5476e"
              )

```


```{r,include=FALSE,message=FALSE}

# reading in the first webpage

medium_slug <- "https://medium.com/s/cointalk/"

url <- paste0(medium_slug,hand_list[[1]])
testtesttest <- read_html(url)

# pulling only the parts that are attributed to Jay or Aaron

testtibble<- testtesttest %>% 
  html_nodes('p') %>% 
  html_text() %>% 
  as_tibble() %>% 
  filter(str_detect(value,"Jay Kang:")==TRUE |str_detect(value,"Aaron Lammer:")==TRUE) 

# getting the episode number from the webpage

episode <- testtesttest %>% html_nodes('h1') %>% html_text()

# pulling all of the text attributed to Jay and Aaron

text <- testtibble$value
new_text <- unlist(text)

# Each block of text starts with the name of the speaker and then ":" and then what they said.
# The next block splits the text into two lists, one is the name of the speaker and the other is what he said.


test1<- map(new_text,first)
test2<- map(new_text,second)


# this takes the two lists and makes them into a dataframe
conversation_df <- tibble(name = unlist(test1),text = test2)

#adding the row number and the episode number to each row
conversation_df <-  conversation_df %>% mutate(linenumber=row_number(),episode=episode)

# now createing a tibble containing one row for each word.

tidy_conversation <- conversation_df %>% 
  unnest_tokens(word, text) 


# removing stop words

tidy_conversation <- tidy_conversation %>% 
  anti_join(stop_words)

# renaming the tibble 'tidy_conversation_main' which will be where all the tibbles are appended to 

tidy_conversation_main <- tidy_conversation

```


```{r, include=FALSE,message=FALSE}

# creating a number list for each link in the list of podcast links.

hand_listnum <- c(2:length(hand_list))

# episode 24 transcript is not formated correctly so I took it out. 


# a for loop that goes through each link, pulls the html, and does the same parsing and wrangling that was done to the first webpage.

for(number in hand_listnum){
  print(number)
  medium_slug <- "https://medium.com/s/cointalk/"
  url <- paste0(medium_slug,hand_list[[number]])
  testtesttest <- read_html(url)
 
  
  testtibble<- testtesttest %>% 
    html_nodes('p') %>% 
    html_text() %>% 
    as_tibble() %>% 
    filter(str_detect(value,"Jay Kang:")==TRUE | str_detect(value,"Aaron Lammer:")==TRUE 
           |str_detect(value,"Jay:")==TRUE |str_detect(value,"Aaron:")==TRUE) 
  
  episode <- testtesttest %>% html_nodes('h1') %>% html_text()
  print(episode)
  
  text <- testtibble$value
  
  new_text <- unlist(text)
  
  test1<- map(new_text,first)
  test2<- map(new_text,second)
  
  conversation_df <- tibble(name = unlist(test1),text = test2)
  
  conversation_df <-  conversation_df %>% mutate(linenumber=row_number(),episode=episode)
  
  tidy_conversation <- conversation_df %>% 
    unnest_tokens(word, text) 
  
  tidy_conversation <- tidy_conversation %>% 
    anti_join(stop_words)
  
  tidy_conversation_main <- rbind(tidy_conversation_main,tidy_conversation)
  
}

```

Now we have a table with  "name","linenumber","episode","word".  

```{r,message=FALSE}
head(tidy_conversation_main)

```

I join three sentiment tables to that table, one from Bing, one from Afinn, and one from NRC.  


We can see the total number of non-stop words Aaron and Jay have used:

```{r,include=FALSE,message=FALSE}
tidy_conversation_main <- tidy_conversation_main %>% 
  mutate(name = ifelse(name=="Aaron Lammer","Aaron",
                ifelse(name== "Jay Kang","Jay",name)))

tidy_conversation_main <- tidy_conversation_main %>% 
  filter(name=="Aaron"|name=="Jay")

```

```{r,message=FALSE}




tidy_conversation_main %>% group_by(name) %>% tally()

```



```{r,include=FALSE,message=FALSE}



# taking out the word 'grin' since it referes to a coin and not the actually grining, which is positive

tidy_conversation_main <- tidy_conversation_main %>% 
                          filter(word != 'grin')

tidy_conversation_main <- tidy_conversation_main %>%
mutate(episode_number = ifelse(is.na(str_extract(episode,'[:digit:]{2}')),str_extract(episode,'[:digit:]'),str_extract(episode,'[:digit:]{2}'))%>% as.numeric())


# bringing in all of the bing sentiment words
bing  <- get_sentiments('bing')
afinn <- get_sentiments('afinn')
nrc   <- get_sentiments('nrc')

# joining the sentiment word table to the coin talk table


convo_w_bing <- tidy_conversation_main %>%
  # With inner join, implement sentiment analysis using `bing`
                inner_join(bing)

convo_w_afinn   <- tidy_conversation_main  %>%
  # With inner join, implement sentiment analysis using `bing`
  inner_join(afinn)

colnames(nrc)[2] <- 'nrc_sentiment'

convo_w_ncr      <- tidy_conversation_main  %>%
  # With inner join, implement sentiment analysis using `bing`
  inner_join(nrc)



# coding negative as a zero and positive sentiment as a one.

convo_w_bing <- convo_w_bing %>% mutate(bing_score = ifelse(sentiment == 'negative',-1,1))


# a couple of the episodes either just said the speakers first name instead of their full name. 


summary_of_episode_bing <- convo_w_bing %>%  
                      group_by(name,episode_number) %>%
                      summarize(bing_total=sum(bing_score,na.rm=TRUE)) %>%
                      left_join(.,(convo_w_bing %>%                      
                      group_by(name,episode_number) %>% 
                      tally())) %>%
                      mutate(bing_sentiment_score = bing_total/n) %>%
                      select(name,episode_number,bing_sentiment_score)



                                
summary_of_episode_afinn <- convo_w_afinn %>%  
                            group_by(name,episode_number) %>%
                            summarize(afinn_total = sum(score,na.rm=TRUE)) %>%
                            left_join(.,(convo_w_bing %>%                      
                            group_by(name,episode_number) %>% 
                            tally())) %>%
                            mutate(afinn_sentiment_score = afinn_total/n) %>%
                            select(name,episode_number,afinn_sentiment_score)


summary_of_episode <- summary_of_episode_bing %>%
                      left_join(summary_of_episode_afinn)
                                
                                




```


The first graph shows the over Bing sentiment score showing the percentage positive words as a total of non-stop words over time.


Please note that I had to take the word 'grin' out of the analysis, since it is refering to a  coin, and not to them grinning all the time. 

```{r, echo=FALSE,message=FALSE}

ggplot(summary_of_episode,aes(episode_number,bing_sentiment_score,color=name)) +
  geom_point() +
  geom_smooth(method='lm')

```

It looks like Aaron starts out more positive than Jay, but over time the two seem to start to converage. 



afinn_sentiment_score 

Using the Afinn table, there is a different trend, showing Jay trend upwards over time, overtaking Aaron interms of percentage of workds that are positive. 

```{r, echo=FALSE,message=FALSE}

ggplot(summary_of_episode,aes(episode_number,afinn_sentiment_score,color=name)) +
  geom_point() +
  geom_smooth(method='lm')

```




Fear  

There's a lot to be afraid of in the crypto world. This graph uses the NRC sentiment table to show the percentage of fear words over time. 


```{r, echo=FALSE,message=FALSE}

unique_ncr <- convo_w_ncr %>% select(name,word,episode_number) %>% unique(.)

denominator_table_ncr <- unique_ncr %>% group_by(name,episode_number)  %>% tally()


 fear_graph_df_numerator <- convo_w_ncr %>% filter(nrc_sentiment=='fear') %>% group_by(name,episode_number,nrc_sentiment) %>% tally()

fear_graph_df <- left_join(fear_graph_df_numerator,denominator_table_ncr)


ggplot(fear_graph_df,aes(episode_number,fear_score,color=name)) +
  geom_point()+
  geom_smooth(method='lm')

```


Looks like Aaron has caught up to Jay.  


Joy  



```{r, echo=FALSE,message=FALSE}

joy_graph_df_numerator  <- convo_w_ncr %>% 
  filter(nrc_sentiment=='joy') %>% 
  group_by(name,episode_number,nrc_sentiment) %>% 
  tally()

joy_graph_df <- left_join(joy_graph_df_numerator,denominator_table_ncr)

joy_graph_df <-joy_graph_df %>% mutate(joy_score = n/denominator)

ggplot(joy_graph_df,aes(episode_number,joy_score,color=name)) +
  geom_point()+
  geom_smooth(method='lm')

```

Although there are more words about fear, there are also more words about joy from Aaron.



 
 Anger  
 
```{r, echo=FALSE,message=FALSE}

anger_graph_df_numerator <- convo_w_ncr %>% filter(nrc_sentiment=='anger') %>% group_by(name,episode_number,nrc_sentiment) %>% tally()

anger_graph_df <- left_join(anger_graph_df_numerator,denominator_table_ncr)

anger_graph_df <-anger_graph_df %>% mutate(anger_score = n/denominator)


ggplot(anger_graph_df,aes(episode_number,anger_score,color=name)) +
  geom_point()+
  geom_smooth(method='lm')

```


Jay's angry, but Aaron's catching up. 



Next steps :

Tf/idf  
LDA   
Adding more documents - Breakermag, chain letter from MIT  
Ngram : looking at ngram with 'pretty'  to see if it ends up more with "pretty good", "pretty bad", or something like "this new coin company is pretty sleazy". This might throw things off since in the bing sentiment table it is coded as positive.  

```{r}

tidy_conversation_main %>% filter(word=='pretty') %>% group_by(name) %>% tally()


```